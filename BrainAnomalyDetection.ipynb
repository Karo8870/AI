{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "L4",
   "authorship_tag": "ABX9TyNYyvsCs0dzwRcVvhRVBBxq"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUOTmoGBSjWp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719219320554,
     "user_tz": -180,
     "elapsed": 26291,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    },
    "outputId": "26484713-8fb8-4559-ba46-3db7a41ca69a",
    "ExecuteTime": {
     "end_time": "2024-06-24T13:33:08.442757Z",
     "start_time": "2024-06-24T13:33:08.220279Z"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip /content/drive/MyDrive/unibuc-brain-ad.zip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAeo9Z5qUIXZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719219372252,
     "user_tz": -180,
     "elapsed": 46660,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    },
    "outputId": "54be3fd2-67f5-4fe9-a5aa-d28882b2eaec",
    "ExecuteTime": {
     "end_time": "2024-06-24T13:33:08.442757Z",
     "start_time": "2024-06-24T13:33:08.442757Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms.functional import adjust_contrast\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision.transforms import v2"
   ],
   "metadata": {
    "id": "vavSHg_0T0wr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719223944520,
     "user_tz": -180,
     "elapsed": 1095,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-24T13:33:08.442757Z",
     "start_time": "2024-06-24T13:33:08.442757Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class CTImages(Dataset):\n",
    "    def __init__(self, filename, root_dir, eqn=True, train=True):\n",
    "        self.annotations = pd.read_csv(filename, skipinitialspace=True, dtype={'id': 'string', 'class': 'int8'}).to_numpy()\n",
    "        if eqn == True:\n",
    "            tr = []\n",
    "            fl = []\n",
    "            for x in self.annotations:\n",
    "                if x[1] == 1:\n",
    "                    tr.append(x)\n",
    "                else:\n",
    "                    fl.append(x)\n",
    "\n",
    "            self.annotations = np.append(fl, [tr, tr])\n",
    "            self.annotations = self.annotations.reshape(len(self.annotations) // 2, 2)\n",
    "        # self.annotations = self.annotations.reshape(len(self.annotations) // 2, 2)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = None\n",
    "        if train:\n",
    "          self.transform = torch.nn.Sequential(\n",
    "              T.RandomHorizontalFlip(p=0.5),\n",
    "              # T.RandomAffine(degrees=6.0, translate=(0.1, 0.1), scale=(0.90, 1.0), fill=-1.0),\n",
    "              # T.ColorJitter())\n",
    "          )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # return 10\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, f'{self.annotations[index][0]}.png')\n",
    "        image = io.imread(img_path)\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0\n",
    "        image = torch.permute(image, (2, 0, 1))\n",
    "        y_label = torch.tensor(int(self.annotations[index][1]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y_label\n",
    "\n",
    "\n",
    "train_set = CTImages(filename='/content/data/train_labels.txt', root_dir='/content/data/data', eqn=False, train=True)\n",
    "test_set = CTImages(filename='/content/data/validation_labels.txt', root_dir='/content/data/data', eqn=False, train=False)\n",
    "\n",
    "# Batch Size -> 4 8 16 32\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=50, shuffle=False)"
   ],
   "metadata": {
    "id": "6pghIa6gTPsW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719227117178,
     "user_tz": -180,
     "elapsed": 1058,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-24T13:33:08.442757Z",
     "start_time": "2024-06-24T13:33:08.442757Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "# MobileNet (224 x 224 x 3)\n",
    "model = mobilenet_v3_large(weights = None)\n",
    "model.classifier = nn.Sequential(*list(model.classifier.children())[:-1], nn.Linear(in_features=1280,out_features=2))\n",
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlz2Sd7RVN4Y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719226175912,
     "user_tz": -180,
     "elapsed": 886,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    },
    "outputId": "ba6dc50c-64f1-4e96-9642-e934d4c2b221"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, 5)\n",
    "        self.fc1 = nn.Linear(53 * 53 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "def init_weights(m):\n",
    "  if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "      torch.nn.init.xavier_uniform(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQZ0TrVcfGvK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719226178345,
     "user_tz": -180,
     "elapsed": 2,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    },
    "outputId": "2e971259-639a-4ed9-e633-1c1f0cb63f07"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Cross Entropy\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9) # Learning Rate 0.01 / 0.001     # - Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)                 # Learning Rate 0.001 / 0.0001\n",
    "loss_fn = nn.CrossEntropyLoss(weight = torch.tensor([1, 4], dtype=torch.float32))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "def train_one_epoch(epoch_index, loader):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    true_positives, false_positives, false_negatives = 0, 0, 0\n",
    "\n",
    "    all_pred = []\n",
    "    all_target = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            for t in target:\n",
    "              all_target.append(t)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            for p in pred:\n",
    "              all_pred.append(p)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            true_positives += ((pred == 1) & (target == 1)).sum().item()\n",
    "            false_positives += ((pred == 1) & (target != 1)).sum().item()\n",
    "            false_negatives += ((pred != 1) & (target == 1)).sum().item()\n",
    "\n",
    "    print(\"F1-score: \", classification_report(all_target, all_pred))\n",
    "    test_loss /= len(loader.dataset)\n",
    "    print(\n",
    "        f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%\\n)')\n",
    "    return true_positives, false_positives, false_negatives"
   ],
   "metadata": {
    "id": "jvfNwcjRV-Lf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719230446953,
     "user_tz": -180,
     "elapsed": 481,
     "user": {
      "displayName": "Alexandru Manole",
      "userId": "16000231996200139655"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCH = 30\n",
    "\n",
    "for e in range(EPOCH):\n",
    "  train_one_epoch(e, train_loader)\n",
    "  test(test_loader)"
   ],
   "metadata": {
    "id": "GLac3MTkbVF3"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
